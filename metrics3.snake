

import os
import csv
from datetime import datetime
from collections import defaultdict

with open(config.get('project',{}).get('sample_list','samples.list'),'r') as i:
    SAMPLES=i.read().splitlines()

with open(config.get('project',{}).get('bam_list','bams.list'),'r') as b:
    BAMS=dict(line.split('\t') for line in b.read().splitlines())

def sample_bam(wildcards):
    return BAMS[wildcards.sample]

header='SAMPLE BAIT_SET TOTAL_READS PCT_PF_READS PF_HQ_ALIGNED_READS PCT_READS_ALIGNED_IN_PAIRS'.split(' ')
if config['resources'].get('disambiguate',False):
    header+=['PCT_HUMAN','PCT_MOUSE','PCT_AMBIGUOUS']
header+=['PCT_DUP']
header+='PCT_SELECTED_BASES MEAN_TARGET_COVERAGE MEDIAN_TARGET_COVERAGE MAX_TARGET_COVERAGE PCT_USABLE_BASES_ON_TARGET ZERO_CVG_TARGETS_PCT PCT_TARGET_BASES_lt_20X PCT_TARGET_BASES_40X PCT_TARGET_BASES_100X'.split(' ')

localrules:Summary

rule standard_summary:
    input:
        expand('{project}.{targets}.{date}.metrics_summary.csv',project=config['project']['name'],targets=config['resources']['targets_key'],date=datetime.today().strftime('%Y%m%d'))

###############################################

rule CollectAlignmentSummaryMetrics:
    input:
        sample_bam
    output:
        "bam_input/final/{sample}/{reference}/metrics/alignment_summary.metrics"
    params:
        reference=config['reference']['fasta'],
        memory="10240m"
    shell:
        "java -Xmx{params.memory} -jar $HOME/software/picard/2.20.7/picard.jar CollectAlignmentSummaryMetrics R={params.reference} I={input} O={output} VALIDATION_STRINGENCY=SILENT"

rule CollectInsertSizeMetrics:
    input:
        sample_bam
    output:
        "bam_input/final/{sample}/{reference}/metrics/insert_size.metrics",
        "bam_input/final/{sample}/{reference}/metrics/insert_size_histogram.pdf"
    params:
        reference=config['reference']['fasta'],
        memory="10240m",
        MINIMUM_PCT=0.5
        #Default value = 0.05. but documentation states "If processing a small file, set the minimum percentage option (M) to 0.5, otherwise an error may occur."
    shell:
        "java -Xmx{params.memory} -jar $HOME/software/picard/2.20.7/picard.jar CollectInsertSizeMetrics R={params.reference} I={input} O={output[0]} H={output[1]} M={params.MINIMUM_PCT} VALIDATION_STRINGENCY=SILENT"

rule CollectHsMetrics:
    input:
        sample_bam
    output:
        "bam_input/final/{sample}/{reference}/metrics/target.metrics",
        "bam_input/final/{sample}/{reference}/metrics/target_coverage.metrics"
    params:
        reference=config['reference']['fasta'],
        baits=config['resources']['picard_intervals'],
        targets=config['resources']['picard_intervals'],
        memory="10240m"
    wildcard_constraints:
        target=config['resources']['targets_key']
    shell:
        "java -Xmx{params.memory} -jar $HOME/software/picard/2.20.7/picard.jar CollectHsMetrics R={params.reference} I={input} O={output[0]} COVERAGE_CAP=1000 BAIT_INTERVALS={params.baits} TARGET_INTERVALS={params.targets} PER_TARGET_COVERAGE={output[1]} VALIDATION_STRINGENCY=SILENT"

rule Samtools_flagstat:
    input:
        sample_bam
    output:
        "bam_input/final/{sample}/{reference}/metrics/flagstat.metrics"
    shell:
        "samtools flagstat {input} > {output}"

rule Summary:
    input:
        expand("bam_input/final/{sample}/{reference}/metrics/alignment_summary.metrics",sample=SAMPLES,reference=config['reference']['key']),
        expand("bam_input/final/{sample}/{reference}/metrics/target.metrics",sample=SAMPLES,reference=config['reference']['key']),
        expand("bam_input/final/{sample}/{reference}/metrics/flagstat.metrics",sample=SAMPLES,reference=config['reference']['key'])
    output:
        csv='{project}.{date}.metrics_summary.csv'
    params:
        PDX=str('disambiguate' in config),
        sample_list=config['project']['sample_list'],
        ref=config['reference']['key']
    script:
        'metrics_summary.py'

rule Target_Coverage_Summary:
    input:
        expand("bam_input/final/{sample}/{reference}/metrics/target_coverage.metrics",sample=SAMPLES,reference=config['reference']['key'])
    output:
        expand('{project}.{date}.mean_target_coverage.txt',project=config['project']['name'],date=datetime.today().strftime('%Y%m%d'))
    run:
        target_coverage=defaultdict(lambda: defaultdict(float))
        sample_file=defaultdict(str)
        key_order=[]
        for sample in SAMPLES:
            sample_file[sample]=[x for x in input if sample in x][0]
            with open(sample_file[sample],'r') as cov_file:
                reader=csv.DictReader(cov_file,delimiter='\t')
                for row in reader:
                    key=tuple([row[x] for x in ['chrom','start','end','length','name']])
                    if key not in key_order:
                        key_order.append(key)
                    target_coverage[key][sample]=float(row['mean_coverage'])
        with open(output[0],'w') as outfile:
            writer=csv.writer(outfile,delimiter='\t')
            writer.writerow(['Chr','Start','End','Length','Name']+SAMPLES)
            for key in key_order:
                row=list(key)+[target_coverage[key][sample] for sample in SAMPLES]
                writer.writerow(row)